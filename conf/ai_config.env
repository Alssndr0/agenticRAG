# AI Configuration Environment File

# A JSON string mapping model keys to their names.
EMBEDDING_MODEL="bge-large-en-v1.5"
EMBEDDING_MODEL_VERSION = "v0.0.1"

# A JSON string mapping model keys to the directory paths.
EMBEDDING_MODEL_DIR="../resources/ai-models/v0.0.1/bge-large-en-v1.5"

LLM_URL=""

# this is for LLAMA
# LLM_TEMPLATE="<|begin_of_text|><|start_header_id|>system<|end_header_id|>
# $LLM_SYSTEM_MESSAGE<|eot_id|><|start_header_id|>user<|end_header_id|>
# $LLM_PROMPT<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"

# this is for Qwen
LLM_TEMPLATE="<|im_start|>system\n$LLM_SYSTEM_MESSAGE<|im_end|>\n<|im_start|>user\n$LLM_PROMPT<|im_end|>\n<|im_start|>assistant\n"

LLM_SYSTEM_MESSAGE="You are a helpful assistant who provides an answer to the original question, based on the documentation you are given. \
If you don't find any relevant information to answer the original question, just say that you couldn't find any mention of that in the provided documentation."

LLM_PROMPT="Start Documentation\n{documents}\nEnd Documentation\n{question}\nDon't make any assumptions or reflections, only extract the information as it appears in the document. \
Answer in the form of 'We' since we are company answering customers questions."

LLM_MAX_NEW_TOKENS= 500
LLM_TEMPERATURE=0.01
LLM_SEED=1234
LLM_STREAM= False
